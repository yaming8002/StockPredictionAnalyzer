import pandas as pd
from collections import defaultdict, Counter
import numpy as np
import pandas as pd
import statistics
from scipy import stats
import logging
# è®€å– CSVï¼ˆè«‹æ›æˆä½ çš„å¯¦éš›æª”æ¡ˆè·¯å¾‘ï¼‰
# file_path = "./stock_data/leaning_label/opt_sma_120_sma_200_year_3_sell_3_AVG_trades.csv"
# df = pd.read_csv(file_path, parse_dates=["buy_date", "sell_date"])

# # ç”¨ dict çµ±è¨ˆæ¯ä¸€å¤©è¢«å¹¾ç­†äº¤æ˜“è¦†è“‹
# overlap_counter = defaultdict(int)

# # æ¯ä¸€ç­†äº¤æ˜“ï¼ŒæŠŠæŒæœ‰æœŸé–“çš„æ¯ä¸€å¤©éƒ½è¨˜ä¸‹ä¾†
# for _, row in df.iterrows():
#     for date in pd.date_range(row["buy_date"], row["sell_date"]):
#         overlap_counter[date.date()] += 1

# # æ•´ç†æˆ DataFrame
# overlap_df = pd.DataFrame(overlap_counter.items(), columns=["date", "overlap_count"])

# # æ‰¾å‡ºé‡ç–Šæœ€å¤šçš„æ—¥æœŸï¼ˆä¾‹å¦‚å‰ 10 åï¼‰
# top_overlap = overlap_df.sort_values(by="overlap_count", ascending=False).head(10)

# print("ðŸ”º é‡ç–Šæœ€å¤šçš„æ—¥æœŸï¼ˆäº¤æ˜“é‡ç–Šæ¬¡æ•¸æœ€å¤šï¼‰ï¼š")
# print(top_overlap)

# # è¨ˆç®—å¹³å‡é‡ç–Šæ¬¡æ•¸
# average_overlap = overlap_df["overlap_count"].mean()
# print(f"\nðŸ“Š å¹³å‡æ¯æ—¥é‡ç–Šäº¤æ˜“æ¬¡æ•¸ï¼š{average_overlap:.2f}")

# # è¨ˆç®—çœ¾æ•¸ï¼ˆæœ€å¸¸è¦‹çš„é‡ç–Šæ¬¡æ•¸ï¼‰
# mode_overlap = overlap_df["overlap_count"].mode()
# if len(mode_overlap) == 1:
#     print(f"ðŸŽ¯ æœ€å¸¸è¦‹çš„é‡ç–Šæ¬¡æ•¸ï¼ˆçœ¾æ•¸ï¼‰ï¼š{mode_overlap.iloc[0]}")
# else:
#     print(f"ðŸŽ¯ æœ€å¸¸è¦‹çš„é‡ç–Šæ¬¡æ•¸ï¼ˆçœ¾æ•¸å€‘ï¼‰ï¼š{', '.join(map(str, mode_overlap.tolist()))}")



def analyze_hold_days(hold_days, log=None):
    """
    åˆ†æžæŒæœ‰å¤©æ•¸åˆ†å¸ƒï¼ŒæŽ’é™¤æ¥µç«¯å€¼å¾Œè¼¸å‡ºæ›´ç©©å¥çš„çµ±è¨ˆè³‡æ–™ã€‚
    
    åƒæ•¸:
        hold_days (list[int/float]): æ¯ç­†äº¤æ˜“çš„æŒæœ‰å¤©æ•¸åˆ—è¡¨
        log (logging.Logger, optional): è‹¥æä¾› loggerï¼Œæœƒè‡ªå‹•è¼¸å‡ºåˆ†æžçµæžœ

    å›žå‚³:
        dict: åŒ…å«åŽŸå§‹çµ±è¨ˆã€åŽ»æ¥µå€¼å¾Œçµ±è¨ˆçš„å­—å…¸
    """
    if not hold_days:
        msg = "ç„¡æŒæœ‰å¤©æ•¸æ•¸æ“š"
        if log:
            log.info(msg)
        return {"message": msg}

    df_days = pd.Series(hold_days)

    # --- 1ï¸âƒ£ åŽŸå§‹çµ±è¨ˆ ---
    raw_max = df_days.max()
    raw_min = df_days.min()
    raw_mean = df_days.mean()
    raw_std = df_days.std(ddof=1)

    # --- 2ï¸âƒ£ åŽ»é™¤æ¥µå€¼ (IQR æ³•) ---
    Q1 = df_days.quantile(0.25)
    Q3 = df_days.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    filtered_days = df_days[(df_days >= lower_bound) & (df_days <= upper_bound)]

    # --- 3ï¸âƒ£ ç©©å¥çµ±è¨ˆ (Robust Statistics) ---
    median_days = filtered_days.median()
    mad_days = stats.median_abs_deviation(filtered_days, scale="normal")
    trimmed_mean = stats.trim_mean(filtered_days, 0.1)
    try:
        mode_days = statistics.mode(filtered_days)
    except statistics.StatisticsError:
        mode_days = "ç„¡å”¯ä¸€çœ¾æ•¸"

    # --- 4ï¸âƒ£ è¼¸å‡ºçµ±è¨ˆçµæžœ ---
    summary = {
        "raw": {
            "count": len(df_days),
            "max": float(raw_max),
            "min": float(raw_min),
            "mean": float(raw_mean),
            "std": float(raw_std),
        },
        "filtered": {
            "count": int(len(filtered_days)),
            "median": float(median_days),
            "mad": float(mad_days),
            "trimmed_mean": float(trimmed_mean),
            "mode": mode_days,
            "iqr_lower": float(lower_bound),
            "iqr_upper": float(upper_bound),
        },
    }

    # --- 5ï¸âƒ£ è¼¸å‡ºåˆ° logger ---
    if log:
        log.info("ðŸ“Š æŒæœ‰å¤©æ•¸çµ±è¨ˆï¼ˆå«æ¥µå€¼æŽ’é™¤åˆ†æžï¼‰")
        log.info(
            f"åŽŸå§‹: æœ€å¤§ {raw_max}, æœ€å° {raw_min}, å¹³å‡ {raw_mean:.2f}, æ¨™æº–å·® {raw_std:.2f}"
        )
        log.info(
            f"åŽ»æ¥µå€¼å¾Œ: æ¨£æœ¬ {len(filtered_days)}/{len(df_days)}, "
            f"ä¸­ä½æ•¸ {median_days:.2f}, ä¿®æ­£æ¨™æº–å·®(MAD) {mad_days:.2f}, "
            f"ä¿®å‰ªå¹³å‡ {trimmed_mean:.2f}, çœ¾æ•¸ {mode_days}"
        )

    return summary