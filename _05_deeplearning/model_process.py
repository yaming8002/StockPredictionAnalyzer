import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
from abc import ABC, abstractmethod

from tensorflow.python.data.ops.dataset_ops import DatasetV2

from _04_deeplearning.unit import build_training_data_gen_from_df, build_training_data_gen_one_hot_from_df


class DpTrainerBisis(ABC):

    def __init__(
        self,
        file_path,
        save_path,
        input_shape,
        output_shape,
        optimizer=None,
        is_onehot=False,
        batch_size=64,
        epochs=100,
        patience=5,
    ):
        """
        åˆå§‹åŒ– LSTM Trainer
        """
        self.file_path = file_path
        self.save_path = save_path
        self.input_shape = input_shape
        self.output_shape = output_shape
        self.optimizer = optimizer if optimizer else Adam(learning_rate=0.001)
        self.patience = patience
        self.batch_size = batch_size
        self.is_onehot = is_onehot
        self.epochs = epochs
        self.model = self.build_model()
        if self.is_onehot:
            self.loss_function = "categorical_crossentropy"
        else:
            self.loss_function = "binary_crossentropy"

        self.model.compile(optimizer=self.optimizer, loss=self.loss_function, metrics=["accuracy"])

        # âœ… åˆå§‹åŒ–æ­·å²ç´€éŒ„
        self.history = {"accuracy": [], "loss": [], "val_accuracy": [], "val_loss": []}
        print("âœ… æ¨¡å‹çµæ§‹:")
        self.model.summary()

    @abstractmethod
    def build_model(self):
        """
        æŠ½è±¡æ–¹æ³•ï¼šéœ€è¦è¦†å¯«æ­¤æ–¹æ³•ä¾†è‡ªå®šç¾© LSTM æ¨¡å‹
        """
        pass

    def tranging_model(self):
        """
        è¨“ç·´ä¸¦è©•ä¼°æ¨¡å‹
        """
        print(f"ğŸ“¥ è¼‰å…¥è¨“ç·´è³‡æ–™: {self.file_path}")
        trades = pd.read_csv(self.file_path, parse_dates=["buy_date"])
        split_index = int(len(trades) * 0.95)
        train_trades = trades[:split_index]
        val_trades = trades[split_index:]

        trades = trades.sample(frac=1).reset_index(drop=True)
        # âœ… class_weight è¨­å®š
        win_trades = train_trades[train_trades["profit"] > 0]
        win_per = len(win_trades) / len(train_trades)
        class_weight = {0: 1.0, 1: 1 / win_per}

        self.fit(train_trades, val_trades, class_weight)
        self.evaluate(val_trades)
        self.save_model()
        self.plot_history()

    def fit(self, train_df, val_df, class_weight):
        """
        è¨“ç·´æ¨¡å‹
        """
        print("ğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹...")

        steps_per_epoch = max(len(train_df) // self.batch_size, 1)
        validation_steps = max(len(val_df) // self.batch_size, 1)

        best_loss = float("inf")
        patience_counter = 0

        for epoch in range(self.epochs):
            print(f"\nğŸ”„ Epoch {epoch + 1} é–‹å§‹ï¼Œæ‰“äº‚è³‡æ–™...")
            train_df = train_df.sample(frac=1).reset_index(drop=True)
            print(f"ğŸ”„ è³‡æ–™ç”Ÿæˆå™¨å·²å»ºç«‹, æ‰¹æ¬¡å¤§å°: {self.batch_size}, ä½¿ç”¨ One-Hot: {self.is_onehot}")
            train_dataset = self.create_data_generator(train_df)
            val_dataset = self.create_data_generator(val_df)

            # å–®æ¬¡ Epoch è¨“ç·´
            history_epoch = self.model.fit(train_dataset, steps_per_epoch=steps_per_epoch, class_weight=class_weight, verbose=1)
            val_loss, val_accuracy = self.model.evaluate(val_dataset, steps=validation_steps)

            self.history["accuracy"].append(history_epoch.history["accuracy"][0])
            self.history["loss"].append(history_epoch.history["loss"][0])
            self.history["val_accuracy"].append(val_accuracy)
            self.history["val_loss"].append(val_loss)
            print(f" ğŸ”¸ è¨“ç·´é›† - Loss: {history_epoch.history['loss'][0]}, Accuracy: {history_epoch.history['accuracy'][0]}")
            print(f" ğŸ”¹ é©—è­‰é›† - Loss: {val_loss}, Accuracy: {val_accuracy}")

            # Early Stopping æª¢æŸ¥
            if val_loss < best_loss:
                best_loss = val_loss
                patience_counter = 0
            else:
                patience_counter += 1
                print(f"ğŸ” Early Stopping è¨ˆæ•¸: {patience_counter}/{self.patience}")

            if patience_counter >= self.patience:
                print("ğŸ›‘ è§¸ç™¼ Early Stopping!")
                break

    def create_data_generator(self, dataframe) -> DatasetV2:
        """
        å»ºç«‹è³‡æ–™ç”Ÿæˆå™¨
        """
        if self.is_onehot:
            dataset = tf.data.Dataset.from_generator(
                lambda: build_training_data_gen_one_hot_from_df(dataframe),
                output_signature=(
                    tf.TensorSpec(shape=(30, 19), dtype=tf.float32),
                    tf.TensorSpec(shape=(2,), dtype=tf.int32),
                ),
            )
        else:
            dataset = tf.data.Dataset.from_generator(
                lambda: build_training_data_gen_from_df(dataframe),
                output_signature=(
                    tf.TensorSpec(shape=(30, 19), dtype=tf.float32),
                    tf.TensorSpec(shape=(), dtype=tf.int32),
                ),
            )

        # ğŸš€ è‡ªå‹•èª¿æ•´ buffer size é¿å…è¶…å‡ºç¯„åœ
        dataset = dataset.batch(self.batch_size)
        dataset = dataset.prefetch(tf.data.AUTOTUNE)
        return dataset

    def evaluate(self, val_df):
        """
        è©•ä¼°æ¨¡å‹
        """
        print("ğŸ“Š é–‹å§‹æ¨¡å‹è©•ä¼°...")
        val_dataset = self.create_data_generator(val_df)
        loss, acc = self.model.evaluate(val_dataset)
        print(f"ğŸ“Š æ¸¬è©¦é›†æº–ç¢ºç‡: {acc:.4f}, æå¤±: {loss:.4f}")
        return loss, acc

    def save_model(self):
        """
        å„²å­˜æ¨¡å‹
        """
        self.model.save(self.save_path, include_optimizer=True)
        print(f"âœ… æ¨¡å‹å·²å„²å­˜è‡³: {self.save_path}")

    def plot_history(self):
        """
        ç¹ªè£½è¨“ç·´éç¨‹
        """
        plt.figure(figsize=(12, 5))
        plt.plot(self.history["accuracy"], label="Train Accuracy")
        plt.plot(self.history["val_accuracy"], label="Validation Accuracy")
        plt.plot(self.history["loss"], label="Train Loss")
        plt.plot(self.history["val_loss"], label="Validation Loss")
        plt.legend()
        plt.title("è¨“ç·´éç¨‹")
        plt.show()
